"""
ì˜¤ë”ë¶ í”„ë¡œì„¸ìŠ¤ í•¸ë“¤ëŸ¬

ProcessComponentë¥¼ ìƒì†ë°›ì•„ ì˜¤ë”ë¶ í”„ë¡œì„¸ìŠ¤ì˜ ì‹œì‘/ì¢…ë£Œë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
"""

import asyncio
import logging
import time
from typing import Dict, Any, Optional, List, Set
from datetime import datetime, timedelta

from crosskimp.common.logger.logger import get_unified_logger
from crosskimp.common.events.handler.process_component import ProcessComponent
from crosskimp.common.config.common_constants import SystemComponent, EXCHANGE_NAMES_KR
from crosskimp.common.events.system_types import EventChannels, EventValues

# ë©”íŠ¸ë¦­ ëª¨ë“ˆ ì„í¬íŠ¸ ì œê±° (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)

# ì˜¤ë”ë¶ ìˆ˜ì§‘ê¸° ì„í¬íŠ¸
from crosskimp.ob_collector.obcollector import OrderbookCollectorManager

# ë¡œê±° ì„¤ì •
logger = get_unified_logger(component=SystemComponent.OB_COLLECTOR.value)

class OrderbookProcess(ProcessComponent):
    """
    ì˜¤ë”ë¶ ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤
    
    ì˜¤ë”ë¶ ìˆ˜ì§‘ì„ ìœ„í•œ í”„ë¡œì„¸ìŠ¤ ì»´í¬ë„ŒíŠ¸ì…ë‹ˆë‹¤.
    ProcessComponentë¥¼ ìƒì†ë°›ì•„ í”„ë¡œì„¸ìŠ¤ ìƒëª…ì£¼ê¸°ì™€ ìƒíƒœ ê´€ë¦¬ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤.
    ê¸°ìˆ ì  ì‘ì—…ì€ OrderbookCollectorManagerì— ìœ„ì„í•˜ê³ , ì´ í´ë˜ìŠ¤ëŠ” ìƒíƒœ ê´€ë¦¬ë§Œ ë‹´ë‹¹í•©ë‹ˆë‹¤.
    """

    def __init__(self, eventbus=None, config=None):
        """
        ì´ˆê¸°í™”
        
        Args:
            eventbus: ì´ë²¤íŠ¸ ë²„ìŠ¤ ê°ì²´ (ê¸°ë³¸ê°’: None, Noneì¼ ê²½ìš° get_event_bus()ë¡œ ê°€ì ¸ì˜´)
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬ (ê¸°ë³¸ê°’: None, Noneì¼ ê²½ìš° get_config()ë¡œ ê°€ì ¸ì˜´)
        """
        # ë¶€ëª¨ í´ë˜ìŠ¤ ì´ˆê¸°í™” (process_nameê³¼ eventbus ì „ë‹¬)
        super().__init__(process_name="ob_collector", event_bus=eventbus)
        
        # ì„¤ì • ì €ì¥
        from crosskimp.common.config.app_config import get_config
        self.config = config if config is not None else get_config()
        
        # ë°ì´í„° ìˆ˜ì§‘ì„ ìœ„í•œ OrderbookCollectorManager ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        self.collector = OrderbookCollectorManager()
        
        # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ê´€ë ¨ ë³€ìˆ˜
        self.metric_interval = self.config.get("metrics", {}).get("interval", 20)  # ê¸°ë³¸ê°’ 20ì´ˆ
        self.metric_collection_task = None  # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ íƒœìŠ¤í¬ ì°¸ì¡°
        
        # ê±°ë˜ì†Œ ìƒíƒœ ì¶”ì ìš© ë³€ìˆ˜
        self.exchange_uptimes = {}  # ê° ê±°ë˜ì†Œë³„ ì—°ê²° ì‹œì‘ ì‹œê°„
        self.connected_exchanges = set()  # í˜„ì¬ ì—°ê²°ëœ ê±°ë˜ì†Œ
        self.all_connected = False  # ëª¨ë“  ê±°ë˜ì†Œ ì—°ê²° ì—¬ë¶€
        
        # ëª¨ë‹ˆí„°ë§ íƒœìŠ¤í¬ ì°¸ì¡°
        self._monitoring_task = None

        # í…”ë ˆê·¸ë¨ ì£¼ê¸°ì  ì•Œë¦¼ ê´€ë ¨ ì„¤ì •
        self.telegram_status_interval = 10 * 60  # 10ë¶„(ì´ˆ ë‹¨ìœ„)
        self.last_telegram_status_time = 0  # ë§ˆì§€ë§‰ ì•Œë¦¼ ì‹œê°„
        
        # ì´ì „ ë©”íŠ¸ë¦­ ì €ì¥ (ë³€ê²½ì  ê³„ì‚°ìš©)
        self.previous_metrics = {}
        self.last_metric_time = None

    async def _do_start(self) -> bool:
        """
        ì˜¤ë”ë¶ í”„ë¡œì„¸ìŠ¤ ì‹œì‘
        
        Returns:
            bool: ì‹œì‘ ì„±ê³µ ì—¬ë¶€
        """
        try:
            self.logger.info("ì˜¤ë”ë¶ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ì¤‘...")
            self.logger.info("[ë””ë²„ê¹…] _do_start ë©”ì„œë“œ ì‹œì‘")
            
            # 1. ì´ˆê¸°í™” í•„ìš”ì„± í™•ì¸ ë° ìˆ˜í–‰
            if not self.collector.initialization_complete:
                self.logger.info("ì˜¤ë”ë¶ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì‹œì‘")
                self.logger.info("[ë””ë²„ê¹…] collector.initialize í˜¸ì¶œ ì „")
                
                # ì´ˆê¸°í™” ìˆ˜í–‰
                init_success = await self.collector.initialize()
                self.logger.info(f"[ë””ë²„ê¹…] collector.initialize ê²°ê³¼: {init_success}")
                
                if not init_success:
                    self.logger.error("ì˜¤ë”ë¶ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨")
                    return False
                    
                self.logger.info("ì˜¤ë”ë¶ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                self.logger.info("ì˜¤ë”ë¶ ìˆ˜ì§‘ê¸°ê°€ ì´ë¯¸ ì´ˆê¸°í™”ë˜ì–´ ìˆìŒ")
            
            # 2. ê¸°ìˆ ì  ì‘ì—… ì‹œì‘
            self.logger.info("ì˜¤ë”ë¶ ìˆ˜ì§‘ê¸° ì‹œì‘ ìš”ì²­")
            self.logger.info("[ë””ë²„ê¹…] collector.start í˜¸ì¶œ ì „")
            success = await self.collector.start()
            self.logger.info(f"[ë””ë²„ê¹…] collector.start ê²°ê³¼: {success}")
            
            if not success:
                self.logger.error("ì˜¤ë”ë¶ ìˆ˜ì§‘ê¸° ì‹œì‘ ì‹¤íŒ¨")
                return False
                
            # 3. ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œì‘ - ë³€ê²½: ì§ì ‘ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ë°œí–‰
            try:
                self.logger.info("ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œì‘")
                # ObcMetricManager ì´ˆê¸°í™” ì½”ë“œ ì œê±°
                
                # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ íƒœìŠ¤í¬ ì‹œì‘
                self.metric_collection_task = asyncio.create_task(
                    self._collect_and_publish_metrics(self.metric_interval)
                )
                self.logger.info(f"ë©”íŠ¸ë¦­ ìˆ˜ì§‘ íƒœìŠ¤í¬ ì‹œì‘ë¨ (ê°„ê²©: {self.metric_interval}ì´ˆ)")
                
            except Exception as e:
                self.logger.error(f"ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œì‘ ì‹¤íŒ¨: {str(e)}")
                # ë©”íŠ¸ë¦­ ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•Šìœ¼ë¯€ë¡œ ê³„ì† ì§„í–‰
            
            # 4. ìƒíƒœ ëª¨ë‹ˆí„°ë§ íƒœìŠ¤í¬ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)
            self.logger.info("[ë””ë²„ê¹…] ìƒíƒœ ëª¨ë‹ˆí„°ë§ íƒœìŠ¤í¬ ì‹œì‘ ì „")
            self._monitoring_task = asyncio.create_task(self._monitor_collector_status())
            self.logger.info("[ë””ë²„ê¹…] ìƒíƒœ ëª¨ë‹ˆí„°ë§ íƒœìŠ¤í¬ ìƒì„± ì™„ë£Œ")
            
            self.logger.info("ì˜¤ë”ë¶ í”„ë¡œì„¸ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. (ê±°ë˜ì†Œ ì—°ê²°ì€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê³„ì†ë©ë‹ˆë‹¤)")
            self.logger.info("[ë””ë²„ê¹…] _do_start ë©”ì„œë“œ ì¢…ë£Œ, ì„±ê³µ")
            return True
            
        except Exception as e:
            self.logger.error(f"ì˜¤ë”ë¶ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            self.logger.error("[ë””ë²„ê¹…] _do_start ë©”ì„œë“œ ì¢…ë£Œ, ì˜ˆì™¸ ë°œìƒ", exc_info=True)
            return False

    def _format_uptime(self, seconds: float) -> str:
        """ê±°ë˜ì†Œ ì—…íƒ€ì„ì„ ê°€ë…ì„± ìˆëŠ” í˜•íƒœë¡œ í¬ë§·íŒ…"""
        if seconds < 60:
            return f"{int(seconds)}ì´ˆ"
        elif seconds < 3600:
            return f"{int(seconds / 60)}ë¶„ {int(seconds % 60)}ì´ˆ"
        else:
            hours = int(seconds / 3600)
            minutes = int((seconds % 3600) / 60)
            return f"{hours}ì‹œê°„ {minutes}ë¶„"

    def _get_formatted_exchange_status(self, exchange_status: Dict[str, bool]) -> List[Dict[str, Any]]:
        """ëª¨ë“  ê±°ë˜ì†Œ ìƒíƒœ ì •ë³´ë¥¼ í¬ë§·íŒ…"""
        exchanges_info = []
        
        # ì§€ì›í•˜ëŠ” ê±°ë˜ì†Œ ëª©ë¡ (í•„í„°ë§ëœ ê±°ë˜ì†Œ ëª©ë¡ì´ ìˆìœ¼ë©´ ì‚¬ìš©)
        supported_exchanges = list(self.collector.filtered_symbols.keys() if hasattr(self.collector, 'filtered_symbols') else exchange_status.keys())
        
        # ConnectionManagerì—ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        connection_metrics = self.collector.connection_manager.get_connection_metrics()
        subscription_metrics = self.collector.connection_manager.get_subscription_metrics()
        
        for exchange in supported_exchanges:
            is_connected = exchange_status.get(exchange, False)
            
            # ConnectionManagerì—ì„œ ì—…íƒ€ì„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            uptime_seconds = 0
            uptime_formatted = "ì—°ê²° ì•ˆë¨"
            
            if exchange in connection_metrics:
                uptime_seconds = connection_metrics[exchange].get("uptime", 0)
                uptime_formatted = connection_metrics[exchange].get("uptime_formatted", "ì—°ê²° ì•ˆë¨")
                
            # ê±°ë˜ì†Œ í‘œì‹œëª… ê°€ì ¸ì˜¤ê¸° (í•œê¸€ëª… ìˆìœ¼ë©´ ì‚¬ìš©)
            exchange_name = EXCHANGE_NAMES_KR.get(exchange, exchange)
            
            # êµ¬ë… ì‹¬ë³¼ ìˆ˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            subscribed_symbols_count = 0
            
            # ConnectionManagerì—ì„œ êµ¬ë… ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            if exchange in subscription_metrics:
                subscribed_symbols_count = subscription_metrics[exchange].get("total_symbols", 0)
            
            exchanges_info.append({
                "name": exchange,
                "display_name": exchange_name,
                "connected": is_connected,
                "uptime_seconds": uptime_seconds,
                "uptime_formatted": uptime_formatted,
                "subscribed_symbols_count": subscribed_symbols_count
            })
            
        return exchanges_info

    async def _monitor_collector_status(self):
        """ì˜¤ë”ë¶ ìˆ˜ì§‘ê¸°ì˜ ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê³  ì´ë²¤íŠ¸ ë°œí–‰"""
        self.logger.info("ì˜¤ë”ë¶ ìˆ˜ì§‘ê¸° ìƒíƒœ ëª¨ë‹ˆí„°ë§ íƒœìŠ¤í¬ ì‹œì‘")
        
        # ì´ˆê¸° ìƒíƒœ ì €ì¥
        prev_exchange_status = {}
        check_count = 0
        all_connected_event_sent = False
        current_time = time.time()
        
        # í…”ë ˆê·¸ë¨ ë…¸í‹°íŒŒì´ì–´ ê°€ì ¸ì˜¤ê¸°
        from crosskimp.telegram_bot.notify import get_telegram_notifier
        from crosskimp.telegram_bot.notify_formatter import NotificationLevel
        telegram_notifier = get_telegram_notifier()
        
        # ìƒíƒœ ëª¨ë‹ˆí„°ë§ ë£¨í”„
        while True:
            try:
                # í”„ë¡œì„¸ìŠ¤ê°€ ì‹œì‘ ì¤‘ì´ ì•„ë‹ˆê±°ë‚˜ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ê²½ìš° (ìƒíƒœê°€ ë³€ê²½ëœ ê²½ìš°) ëª¨ë‹ˆí„°ë§ ì¤‘ë‹¨
                if not self.is_starting and not self.is_running:
                    self.logger.info("í”„ë¡œì„¸ìŠ¤ê°€ ì‹œì‘ ì¤‘ ë˜ëŠ” ì‹¤í–‰ ì¤‘ ìƒíƒœê°€ ì•„ë‹ˆë¯€ë¡œ ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ")
                    break
                
                check_count += 1
                current_time = time.time()
                
                # ê±°ë˜ì†Œ ì—°ê²° ìƒíƒœ ê°€ì ¸ì˜¤ê¸° - ConnectionManagerë¥¼ ë‹¨ì¼ ì§„ì‹¤ ì›ì²œìœ¼ë¡œ ì‚¬ìš©
                exchange_status = self.collector.get_exchange_status()
                
                # ê±°ë˜ì†Œ ì—°ê²° ìƒíƒœì— ë”°ë¼ self.exchange_uptimes ì—…ë°ì´íŠ¸
                for exchange, is_connected in exchange_status.items():
                    # ì—°ê²°ëœ ê±°ë˜ì†Œì˜ ê²½ìš° ì‹œì‘ ì‹œê°„ ê¸°ë¡
                    if is_connected:
                        if exchange not in self.exchange_uptimes:
                            self.logger.debug(f"ê±°ë˜ì†Œ '{exchange}' ì²« ì—°ê²° ê°ì§€, ì—…íƒ€ì„ ê¸°ë¡ ì‹œì‘")
                            self.exchange_uptimes[exchange] = current_time
                        elif exchange not in self.connected_exchanges:
                            self.logger.debug(f"ê±°ë˜ì†Œ '{exchange}' ì¬ì—°ê²° ê°ì§€, ì—…íƒ€ì„ ê°±ì‹ ")
                            self.exchange_uptimes[exchange] = current_time
                        self.connected_exchanges.add(exchange)
                    else:
                        # ì—°ê²° ëŠê¸´ ê±°ë˜ì†ŒëŠ” ì—°ê²°ëœ ê±°ë˜ì†Œ ëª©ë¡ì—ì„œ ì œê±°
                        if exchange in self.connected_exchanges:
                            self.logger.debug(f"ê±°ë˜ì†Œ '{exchange}' ì—°ê²° ëŠê¹€ ê°ì§€")
                            self.connected_exchanges.discard(exchange)
                            if exchange in self.exchange_uptimes:
                                self.exchange_uptimes.pop(exchange)
                
                # ì „ì²´ ê±°ë˜ì†Œ ìƒíƒœ í¬ë§·íŒ…
                exchanges_info = self._get_formatted_exchange_status(exchange_status)
                
                # ì—°ê²°ëœ ê±°ë˜ì†Œ ìˆ˜ì™€ ì´ ê±°ë˜ì†Œ ìˆ˜
                connected_count = sum(1 for ex in exchanges_info if ex["connected"])
                total_count = len(exchanges_info)
                
                # ëª¨ë“  ê±°ë˜ì†Œ ì—°ê²° ì—¬ë¶€ í™•ì¸
                prev_all_connected = self.all_connected
                self.all_connected = (connected_count == total_count) and (total_count > 0)
                
                # ì£¼ê¸°ì  ë¡œê¹… (5íšŒë§ˆë‹¤)
                if check_count % 5 == 0:
                    self.logger.debug(f"ì˜¤ë”ë¶ ìˆ˜ì§‘ê¸° ìƒíƒœ: {connected_count}/{total_count} ê±°ë˜ì†Œ ì—°ê²°ë¨")
                
                # ê±°ë˜ì†Œ ìƒíƒœ ë³€ê²½ ê°ì§€ - ë” íš¨ìœ¨ì ì¸ ë¹„êµ
                status_changed = False
                
                # ìƒíƒœ ë³€ê²½ ê°ì§€ ë°©ë²• ê°œì„ 
                for exchange, status in exchange_status.items():
                    prev_status = prev_exchange_status.get(exchange, False)
                    if prev_status != status:
                        status_changed = True
                        break
                
                # ëª¨ë“  ê±°ë˜ì†Œ ì²˜ìŒ ì—°ê²°ëœ ê²½ìš°ë„ ìƒíƒœ ë³€ê²½ìœ¼ë¡œ ê°„ì£¼
                if self.all_connected and not prev_all_connected:
                    status_changed = True
                
                # ìƒíƒœ ë³€ê²½ì´ ìˆì„ ë•Œë§Œ ì´ë²¤íŠ¸ ë°œí–‰
                if status_changed:
                    # ì´ë²¤íŠ¸ ë°ì´í„° ì¤€ë¹„
                    event_data = {
                        "process_name": self.process_name,
                        "timestamp": current_time,
                        "details": {
                            "exchanges": exchanges_info,
                            "connected_count": connected_count,
                            "total_count": total_count,
                            "all_connected": self.all_connected
                        }
                    }
                    
                    # ëª¨ë“  ê±°ë˜ì†Œ ì—°ê²°ëœ ê²½ìš° ì´ë²¤íŠ¸ ë°œí–‰ (RUNNING ì´ë²¤íŠ¸ ì œê±°)
                    if self.all_connected and not all_connected_event_sent:
                        all_connected_event_sent = True
                        
                        # í”„ë¡œì„¸ìŠ¤ ìƒíƒœ ë³€ê²½ë§Œ ìœ ì§€ (RUNNING ì´ë²¤íŠ¸ ë°œí–‰í•˜ì§€ ì•ŠìŒ)
                        await self._publish_status(EventValues.PROCESS_RUNNING)
                        self.logger.info("ëª¨ë“  ê±°ë˜ì†Œ ì—°ê²° ì™„ë£Œ, í”„ë¡œì„¸ìŠ¤ ìƒíƒœë¥¼ RUNNINGìœ¼ë¡œ ë³€ê²½")
                    
                    # ê°œë³„ ê±°ë˜ì†Œ ìƒíƒœ ë³€ê²½ ì´ë²¤íŠ¸ ë°œí–‰
                    for exchange_code, is_connected in exchange_status.items():
                        prev_state = prev_exchange_status.get(exchange_code, False)
                        
                        # ì—°ê²° ìƒíƒœê°€ ë³€ê²½ëœ ê²½ìš°ì—ë§Œ ì´ë²¤íŠ¸ ë°œí–‰
                        if prev_state != is_connected:
                            exchange_event_data = {
                                "timestamp": current_time,
                                "exchange": exchange_code,
                                "status": is_connected,
                                "exchanges_info": exchanges_info,
                                "connected_count": connected_count,
                                "total_count": total_count,
                                "all_connected": self.all_connected  # ëª¨ë“  ê±°ë˜ì†Œ ì—°ê²° ìƒíƒœ ì¶”ê°€
                            }
                            
                            # ê±°ë˜ì†Œ ì—°ê²° ëŠê¹€
                            if prev_state and not is_connected:
                                exchange_event_data["reason"] = f"{EXCHANGE_NAMES_KR.get(exchange_code, exchange_code)} ì—°ê²°ì´ ëŠê²¼ìŠµë‹ˆë‹¤"
                                await self.event_bus.publish(EventChannels.Component.ObCollector.CONNECTION_LOST, exchange_event_data)
                                self.logger.info(f"ê±°ë˜ì†Œ '{exchange_code}' ì—°ê²° ëŠê¹€ ì´ë²¤íŠ¸ ë°œí–‰ë¨")
                            
                            # ê±°ë˜ì†Œ ì—°ê²° ì„±ê³µ
                            elif not prev_state and is_connected:
                                await self.event_bus.publish(EventChannels.Component.ObCollector.EXCHANGE_STATUS, exchange_event_data)
                                self.logger.info(f"ê±°ë˜ì†Œ '{exchange_code}' ì—°ê²° ì„±ê³µ ì´ë²¤íŠ¸ ë°œí–‰ë¨")
                
                # í˜„ì¬ ìƒíƒœë¥¼ ì´ì „ ìƒíƒœë¡œ ì €ì¥
                prev_exchange_status = exchange_status.copy()
                
                # 2ì´ˆë§ˆë‹¤ í™•ì¸ (1ì´ˆì—ì„œ 2ì´ˆë¡œ ë³€ê²½í•˜ì—¬ ë¶€í•˜ ê°ì†Œ)
                await asyncio.sleep(2)
                
            except asyncio.CancelledError:
                self.logger.info("ì˜¤ë”ë¶ ìˆ˜ì§‘ê¸° ìƒíƒœ ëª¨ë‹ˆí„°ë§ íƒœìŠ¤í¬ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                break
            except Exception as e:
                self.logger.error(f"ìƒíƒœ ëª¨ë‹ˆí„°ë§ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                await asyncio.sleep(5)  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë” ê¸´ ê°„ê²©ìœ¼ë¡œ ì¬ì‹œë„
                
        self.logger.info("ì˜¤ë”ë¶ ìˆ˜ì§‘ê¸° ìƒíƒœ ëª¨ë‹ˆí„°ë§ íƒœìŠ¤í¬ ì¢…ë£Œ")
        
    async def _do_stop(self) -> bool:
        """
        ì˜¤ë”ë¶ í”„ë¡œì„¸ìŠ¤ ì¤‘ì§€
        
        Returns:
            bool: ì¤‘ì§€ ì„±ê³µ ì—¬ë¶€
        """
        try:
            self.logger.info("ì˜¤ë”ë¶ í”„ë¡œì„¸ìŠ¤ ì¤‘ì§€ ì¤‘...")
            
            # 1. ë©”íŠ¸ë¦­ ìˆ˜ì§‘ íƒœìŠ¤í¬ ì¤‘ì§€
            if self.metric_collection_task:
                try:
                    self.metric_collection_task.cancel()
                    self.logger.info("ë©”íŠ¸ë¦­ ìˆ˜ì§‘ íƒœìŠ¤í¬ ì·¨ì†Œë¨")
                except Exception as e:
                    self.logger.warning(f"ë©”íŠ¸ë¦­ ìˆ˜ì§‘ íƒœìŠ¤í¬ ì·¨ì†Œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                self.metric_collection_task = None
            
            # 2. ìˆ˜ì§‘ê¸° ì¤‘ì§€
            stop_success = await self.collector.stop()
            if not stop_success:
                self.logger.error("ì˜¤ë”ë¶ ìˆ˜ì§‘ê¸° ì¤‘ì§€ ì‹¤íŒ¨")
                return False
            
            self.logger.info("ì˜¤ë”ë¶ í”„ë¡œì„¸ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return True
            
        except Exception as e:
            self.logger.error(f"ì˜¤ë”ë¶ í”„ë¡œì„¸ìŠ¤ ì¤‘ì§€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False

    # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ë°œí–‰ ê´€ë ¨ ë©”ì„œë“œë“¤ - ë‹¨ìˆœí™”
    async def _collect_and_publish_metrics(self, interval: int = 20):
        """
        ë©”íŠ¸ë¦­ ë°ì´í„° ì£¼ê¸°ì  ìˆ˜ì§‘ ë° ì´ë²¤íŠ¸ ë°œí–‰
        
        Args:
            interval: ìˆ˜ì§‘ ê°„ê²©(ì´ˆ)
        """
        try:
            self.logger.info(f"ğŸš€ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ íƒœìŠ¤í¬ ì‹¤í–‰ ì‹œì‘ (ê°„ê²©: {interval}ì´ˆ)")
            self.last_metric_time = time.time()
            
            while self.is_running or self.is_starting:
                try:
                    current_time = time.time()
                    self.logger.debug(f"ë©”íŠ¸ë¦­ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
                    
                    # ì—°ê²° ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
                    connection_metrics = self.collector.connection_manager.get_connection_metrics()
                    
                    # ë©”ì‹œì§€ í†µê³„ ê°€ì ¸ì˜¤ê¸° (data_managerì—ì„œ ì§ì ‘ ê°€ì ¸ì˜´)
                    stats = self.collector.data_manager.get_statistics()
                    
                    # ë©”ì‹œì§€ ë©”íŠ¸ë¦­ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                    message_metrics = {}
                    for exchange, data in stats["exchanges"].items():
                        message_metrics[exchange] = {
                            "total_count": data["raw_messages"],
                            "rate": data["interval_rate"],
                            "error_count": data.get("errors", 0)
                        }
                    
                    # ë©”íŠ¸ë¦­ ë°œí–‰
                    await self._publish_connection_metrics(connection_metrics)
                    await self._publish_message_metrics(message_metrics)
                    
                    # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìƒì„± ë° ë°œí–‰
                    system_metrics = {
                        "status": "process/running" if self.all_connected else "process/starting",
                        "uptime": time.time() - self.start_time if hasattr(self, 'start_time') else 0,
                        "connected_exchanges": len(self.connected_exchanges),
                        "total_exchanges": len(self.collector.filtered_symbols) if hasattr(self.collector, 'filtered_symbols') else 0
                    }
                    await self._publish_system_metrics(system_metrics)
                    
                    # êµ¬ë… ë©”íŠ¸ë¦­ ë°œí–‰
                    subscription_metrics = self.collector.connection_manager.get_subscription_metrics()
                    await self._publish_subscription_metrics(subscription_metrics)
                    
                    # ë¡œê¹…
                    self.logger.debug(f"ë©”íŠ¸ë¦­ ë°ì´í„° ìˆ˜ì§‘ ë° ë°œí–‰ ì™„ë£Œ")
                    
                    # í†µê³„ ìš”ì•½ ë¡œê¹…
                    total_raw_messages = sum(data["raw_messages"] for data in stats["exchanges"].values())
                    total_interval_count = sum(data["interval_count"] for data in stats["exchanges"].values())
                    total_rate = sum(data["interval_rate"] for data in stats["exchanges"].values())
                    
                    self.logger.info(f"ğŸ“Š [ë©”íŠ¸ë¦­ í•©ê³„] {'ì „ì²´ ê±°ë˜ì†Œ':15} | ì´: {total_raw_messages:8d}ê±´ | "
                                 f"ìˆ˜ì‹ : {total_interval_count:6d}ê±´/{stats['interval_seconds']:.1f}ì´ˆ | "
                                 f"ì†ë„: {total_rate:.2f}ê±´/ì´ˆ")
                    
                    # ì§€ì •ëœ ê°„ê²©ë§Œí¼ ëŒ€ê¸°
                    self.logger.debug(f"ë‹¤ìŒ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¹Œì§€ {interval}ì´ˆ ëŒ€ê¸°")
                    await asyncio.sleep(interval)
                    
                except asyncio.CancelledError:
                    self.logger.debug("ë©”íŠ¸ë¦­ ìˆ˜ì§‘ íƒœìŠ¤í¬ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    break
                except Exception as e:
                    self.logger.error(f"ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
                    await asyncio.sleep(10)  # ì˜¤ë¥˜ ë°œìƒ ì‹œ 10ì´ˆ í›„ ì¬ì‹œë„
        
        except asyncio.CancelledError:
            self.logger.debug("ë©”íŠ¸ë¦­ ìˆ˜ì§‘ íƒœìŠ¤í¬ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            self.logger.error(f"ë©”íŠ¸ë¦­ ìˆ˜ì§‘ íƒœìŠ¤í¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        finally:
            self.logger.debug("ë©”íŠ¸ë¦­ ìˆ˜ì§‘ íƒœìŠ¤í¬ ì¢…ë£Œ")

    async def _publish_connection_metrics(self, connection_metrics):
        """ì—°ê²° ë©”íŠ¸ë¦­ ë°œí–‰"""
        if not connection_metrics:
            return
            
        event_data = {
            "process_id": self.process_name,
            "timestamp": time.time(),
            "metric_type": "connection",
            "metrics": connection_metrics
        }
        
        await self.event_bus.publish(
            event_path=f"{EventChannels.Component.ObCollector.METRICS}/connection",
            data=event_data
        )
            
    async def _publish_message_metrics(self, message_metrics):
        """ë©”ì‹œì§€ ë©”íŠ¸ë¦­ ë°œí–‰"""
        if not message_metrics:
            return
            
        event_data = {
            "process_id": self.process_name,
            "timestamp": time.time(),
            "metric_type": "message",
            "metrics": message_metrics
        }
        
        await self.event_bus.publish(
            event_path=f"{EventChannels.Component.ObCollector.METRICS}/message",
            data=event_data
        )
    
    async def _publish_error_metrics(self, error_metrics):
        """ì˜¤ë¥˜ ë©”íŠ¸ë¦­ ë°œí–‰"""
        if not error_metrics:
            return
            
        event_data = {
            "process_id": self.process_name,
            "timestamp": time.time(),
            "metric_type": "error",
            "metrics": error_metrics
        }
        
        await self.event_bus.publish(
            event_path=f"{EventChannels.Component.ObCollector.METRICS}/error",
            data=event_data
        )
        
    async def _publish_system_metrics(self, system_metrics):
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ë°œí–‰"""
        if not system_metrics:
            return
            
        # í•˜ìœ„ ì»´í¬ë„ŒíŠ¸ ìƒíƒœ ì œê±° (ë¶ˆí•„ìš”í•¨)
        if "components" in system_metrics:
            del system_metrics["components"]
            
        event_data = {
            "process_id": self.process_name,
            "timestamp": time.time(),
            "metric_type": "system",
            "metrics": system_metrics
        }
        
        await self.event_bus.publish(
            event_path=f"{EventChannels.Component.ObCollector.METRICS}/system",
            data=event_data
        )
        
    async def _publish_subscription_metrics(self, subscription_metrics):
        """êµ¬ë… ë©”íŠ¸ë¦­ ë°œí–‰"""
        if not subscription_metrics:
            return
            
        # ê° ê±°ë˜ì†Œì— ëŒ€í•´ ì‹¬ë³¼ ìƒì„¸ ì •ë³´ ì œê±°í•˜ê³  ì´ ìˆ˜ë§Œ ìœ ì§€
        simplified_metrics = {}
        for exchange, data in subscription_metrics.items():
            simplified_metrics[exchange] = {
                "active": data.get("active", False),
                "total_symbols": data.get("total_symbols", 0)
            }
            
        event_data = {
            "process_id": self.process_name,
            "timestamp": time.time(),
            "metric_type": "subscription",
            "metrics": simplified_metrics
        }
        
        await self.event_bus.publish(
            event_path=f"{EventChannels.Component.ObCollector.METRICS}/subscription",
            data=event_data
        )

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_instance = None

def get_orderbook_process(eventbus, config=None) -> OrderbookProcess:
    """
    ì˜¤ë”ë¶ í”„ë¡œì„¸ìŠ¤ ì»´í¬ë„ŒíŠ¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    ì‹±ê¸€í†¤ íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬ í•˜ë‚˜ì˜ ì¸ìŠ¤í„´ìŠ¤ë§Œ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        eventbus: ì´ë²¤íŠ¸ ë²„ìŠ¤ ê°ì²´
        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬ (ê¸°ë³¸ê°’: None)
        
    Returns:
        OrderbookProcess: ì˜¤ë”ë¶ í”„ë¡œì„¸ìŠ¤ ì»´í¬ë„ŒíŠ¸ ì¸ìŠ¤í„´ìŠ¤
    """
    global _instance
    if _instance is None:
        _instance = OrderbookProcess(eventbus=eventbus, config=config)
    return _instance

async def initialize_orderbook_process(eventbus, config=None):
    """
    ì˜¤ë”ë¶ í”„ë¡œì„¸ìŠ¤ ì»´í¬ë„ŒíŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    
    Args:
        eventbus: ì´ë²¤íŠ¸ ë²„ìŠ¤ ê°ì²´
        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬ (ê¸°ë³¸ê°’: None)
        
    Returns:
        OrderbookProcess: ì´ˆê¸°í™”ëœ ì˜¤ë”ë¶ í”„ë¡œì„¸ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
    """
    process = get_orderbook_process(eventbus=eventbus, config=config)
    await process.register_event_handlers()
    return process